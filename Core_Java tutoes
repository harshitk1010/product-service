CORE JAVA 
https://medium.com/@madhukaudantha/microservice-architecture-and-design-patterns-for-microservices-e0e5013fd58a microservice pattern
=====
CACHING..

@Cacheable: Caches the result of a method based on its parameters.
@CachePut: Updates the cache with the method’s result.
@CacheEvict: Removes data from the cache.
@Caching: Allows combining multiple caching annotations using a single method.

@Service
public class ProductService {

    @Cacheable(value = "products", key = "#id")
    public Product getProductById(Long id) {
        // Simulate a slow database query
        try {
            Thread.sleep(3000); // Simulates a delay
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return new Product(id, "Sample Product");
    }
}

In this example, the getProductById method is annotated with @Cacheable. The first time the method is called with a specific id, the result is stored in the cache. Subsequent calls with the same id retrieve the result from the cache instead of executing the method again.
@CachePut(value = "products", key = "#product.id")
public Product updateProduct(Product product) {
    // Update product logic
    return product;
}
@CacheEvict(value = "products", key = "#id")
public void deleteProduct(Long id) {
    // Delete product logic
}
@CacheEvict(value = "products", allEntries = true)
public void clearCache() {
    // Logic to clear cache
}
---
Redis Server is Running at Some Address:
Redis Accepts Multiple TCP Connections Through Clients: 
Redis beautifully exploits the fact that network I/O is much time taking then Redis’s in-memory operations (which are atomic) and thus redis can provide high throughput, low latency and this apparent but performant concurrency.

 low latency and high throughput observed in Redis caching--
Cache Expiration: If using an external cache provider, configure cache expiration to avoid stale data. For example, in Redis, you can set TTL (Time-To-Live) for cache entries.

=======================================

SPRING TRANSACTION;
https://medium.com/@alxkm/spring-transactions-best-practices-and-problems-ed2526777716

Transactional management is crucial in any application, especially in Spring-based applications where it plays a pivotal role in ensuring data integrity and consistency.
programmatic and declarative transaction management. Declarative management, using annotations like @Transactional, is generally preferred as it keeps the code cleaner and separates transaction management from business logic.

@Service
public class ProductService {

    @Autowired
    private ProductRepository productRepository;

    @Transactional
    public void updateProductPrice(Long productId, double newPrice) {
        Product product = productRepository.findById(productId);
        if (product != null) {
            product.setPrice(newPrice);
            productRepository.save(product);
        }
    }
}
// updateProductPrice method is annotated with @Transactional, indicating that it should be executed within a transaction. Inside the method, we fetch a Product entity by its ID, update its price, and then save it back to the database. If any exception occurs during the execution of this method, the transaction will be rolled back, ensuring data consistency.

@Transactional(rollbackFor = Exception.class)
    public void updateProductPrice(Long productId, double newPrice) throws ProductNotFoundException {
        Product product = productRepository.findById(productId);
        if (product == null) {
            throw new ProductNotFoundException("Product not found with ID: " + productId);
        }
        try {
            product.setPrice(newPrice);
            productRepository.save(product);
        } catch (Exception e) {
            // Log the exception or perform any necessary cleanup
            // Rollback will occur for any exception due to rollbackFor = Exception.class
            throw new ProductUpdateException("Failed to update product price", e);
        }
Spring-based applications maintain data integrity, scalability, and performance, even under heavy transactional loads..
Ensuring atomicity, consistency, isolation, and durability (ACID properties) in distributed transactions
Declarative Transaction Management: - @Transactional
Choosing the Right Propagation Level: - optimizing performance and resource utilization.
Handling Exceptions Appropriately:  - rollbackFor and noRollbackFor, ensures data consistency and graceful error recovery.
Implementing Retry Logic for Optimistic Locking: - 
Keeping Transactions Short and Simple: -

====================
SPRING PAGINATION
https://medium.com/@AlexanderObregon/paginating-api-results-with-spring-boot-and-spring-data-b00b5cddb41c

GET /items?page=2&size=25&sort=name,asc
@GetMapping("/products")
public PaginatedResponse<Product> getProducts(Pageable pageable) {
    Page<Product> page = productRepository.findAll(pageable);
    return buildPaginatedResponse(page);
}
page.hasNext() and page.hasPrevious() tell you if there are more pages ahead or behind.
 The actual list of results comes from page.getContent(). The current page number is provided by page.getNumber(), and the total number of pages is available through page.getTotalPages(). You can get the full item count from page.getTotalElements(), and the page size that was requested through page.getSize()

===============
KAFKA MULTILPE MICOSERVICE COMMUNICATION-








DSA/JAVA8
=============





==============
collection
https://medium.com/@alxkm/choosing-the-right-collection-in-java-c59784fdc9c8

For Random Access Operations: ArrayList is significantly more efficient.
For Frequent Insertions/Deletions at Arbitrary Positions: LinkedList can be more efficient due to the lack of need to shift elements, but the traversal cost needs to be considered.
For Bulk Operations: ArrayList often performs better due to cache locality and less memory overhead.

HashMap - (Hash table.) - Use Case: Best for cases where fast access and insertion without any specific ordering of elements are required.
LinkedHashMap - (Hash table and doubly-linked list.) - Use Case: Best when iteration order needs to be predictable (e.g., maintaining the order of insertion or access order). Suitable for cache implementations (e.g., LRU cache).
TreeMap (Red-black tree)O(log n) -- Use Case: Best when sorted order of keys is required. Suitable for range queries or when natural ordering of keys is important.

HashMap is the most optimal for general use cases where the order of elements does not matter, providing the fastest insertion, deletion, and lookup operations on average.
LinkedHashMap is optimal when you need to maintain insertion order or access order while still having efficient operations comparable to HashMap.
TreeMap is optimal when you need a map that is always sorted, which is useful for range queries or ordered data.

HashSet  Use Case: Best for cases where you need fast operations and do not care about the order of elements.
Hash table
TreeSet(Red-black tree) -- Use Case: Best when you need the elements to be maintained in a sorted order, which is useful for range queries and ordered data retrieval.

HashSet generally provides better performance for basic operations (add, remove, contains) due to O(1) time complexity on average. TreeSet has higher time complexity ( O(log n)) but maintains elements in sorted order.

======

HOW to monitor memoory..
JVM Tools: 
Third-Party Monitoring Tools:
Heap Dumps:
Logging and Alerting:
Monitoring Java memory usage in production environments is crucial for detecting memory leaks, optimizing performance, preventing OutOfMemoryErrors, troubleshooting performance issues, and ensuring the overall stability and reliability of Java applications.

=======

How Spring AOPWorks
Configuration:

XML-based Configuration: Define aspects and advice in Spring configuration files.
Annotation-based Configuration: Use annotations like @Aspect, @Before, @After, @Around, etc., to define aspects and advice in the code.

1. Logging
AOP can be used to log method entry, exit, and exceptions across various layers of an application without cluttering the business logic with logging code.
2. Transaction Management
AOP can manage transactions declaratively, ensuring that business methods are executed within a transactional context without manually managing transaction boundaries.

logging, security, and transaction management, by separating these concerns from the core business logic

Before advice: Executed before a join point.
After advice: Executed after a join point, regardless of its outcome.
After returning advice: Executed after a join point completes normally.
After throwing advice: Executed if a method exits by throwing an exception.
Around advice: Executed around a join point, allowing to control the method execution and the result.

============

future vs completablefuture..
CompletableFuture provides better exception handling than Future. With Future, you can only check if the computation completed successfully or not. If an exception occurs during the computation, you have to catch it explicitly. In contrast, with CompletableFuture, you can handle exceptions in a more declarative way using methods like exceptionally() and handle().
One of the key differences between Future and CompletableFuture is that Future is a blocking API, whereas CompletableFuture is non-blocking. With a Future object, you must call the get() method to retrieve the result, but this method blocks until the result is available. In contrast, with a CompletableFuture object, you can use various non-blocking methods to retrieve the result, such as thenApply(), thenAccept(), or join().
Future, it is difficult to chain multiple asynchronous operations together or to combine the results of multiple operations. CompletableFuture, on the other hand, provides methods such as thenCompose(), thenCombine(), and allOf() that make it easy to compose multiple asynchronous operations and to handle their results in a non-blocking way.
With a Future object, there is no way to explicitly complete the future. Once you submit a task to an executor service and get a Future object in return, you can only wait for the task to complete. With CompletableFuture, you have more control over the completion of the future. You can complete it explicitly by calling complete(), completeExceptionally(), or cancel() methods.
CompletableFuture<Void> allFutures = CompletableFuture.allOf(future1, future2, future3);

allFutures.thenRun(() -> {
    // All futures completed
    String result1 = future1.join();
    String result2 = future2.join();
    String result3 = future3.join();
    System.out.println(result1 + ", " + result2 + ", " + result3);
});
====
https://praveendandu24.medium.com/kubernetes-tutorial-for-beginners-mastering-the-basics-in-1-hour-332db7b5916b
A Kubernetes Service is an abstraction that defines a stable endpoint to access a group of pods. It allows you to expose your application to other pods within the cluster or to external clients. Services provide load balancing and automatic scaling for the pods behind them, ensuring that the application remains highly available.
kubernatics ingress..
While the service enables internal communication between pods within the cluster, Kubernetes Ingress provides a way to expose your services to external clients outside the cluster. It acts as an external entry point to your applications and enables you to configure routing rules and load balancing for incoming traffic.
Kubernetes Secrets are used to store sensitive information, such as passwords, API keys, or TLS certificates. Secrets are base64-encoded by default and can be mounted as files or used as environment variables in pods.
A Kubernetes Volume is a directory that is accessible to all containers in a pod. It decouples the storage from the containers, ensuring that data persists even if a container is restarted or rescheduled.

In this example, we’ll use a PersistentVolumeClaim (PVC) to dynamically provision a PersistentVolume (PV) and attach it to our database container.
A Kubernetes Deployment is a higher-level abstraction that manages a set of identical pods. It's ideal for stateless applications where individual pods are interchangeable. Deployments provide features like rolling updates, rollback, and scaling, making them suitable for web servers, APIs, and microservices.

===
https://suparnachowdhury.medium.com/mastering-sql-top-interview-questions-and-answers-abe12b6089f6
sql
WHERE is for filtering individual rows, while HAVING is for filtering groups of rows after they’ve been aggregated.

SELECT * FROM customers 
WHERE name LIKE 'A%'

SELECT * FROM products 
WHERE product_name LIKE '%phone%'

self join
in an Employees table with columns like employee_id, name, and manager_id (where manager_id refers to another employee_id), a self-join allows us to match each employee with their respective manager.
-
VARCHAR is more efficient for varying text lengths, while CHAR is better for fixed-length data.
--Removing Duplicate Rows in MySQL Using ROW_NUMBER():
--It requires the same number of columns with matching data types and order. UNION automatically removes duplicate rows, returning only distinct values from the combined tables.
aggregate function - SUM, AVG, and COUNT.
scalar function - Scalar functions  - UPPER, LOWER, and LEN.

database transaction & ACID 
maintaining data integrity and consistency in the database.
======
spring mvc
interceptor and filter
When to Use a Filter?
Use Filters for general request/response modifications that apply to all HTTP requests, such as:

Logging: Track request and response details for debugging and monitoring.
GZIP Compression: Reduce response size for faster data transfer.
Character Encoding: Ensure proper text encoding (e.g., UTF-8) for consistency.
Security Checks: Implement firewalls, rate limiting, and access control.
Request/Response Modification: Alter HTTP data (e.g., wrapping, sanitization, caching).
--
If your task involves modifying raw HTTP requests (headers, encoding, compression) → Use a Filter.
If you need to add logic before or after a controller executes → Use an Interceptor.
---======
filter..
@Component
public class LoggingFilter implements Filter {
    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)
        throws IOException, ServletException {
        System.out.println("Request received: " + request.getRemoteAddr());
        chain.doFilter(request, response);
        System.out.println("Response sent.");
    }
}
interceptor--
@Component
public class AuthInterceptor implements HandlerInterceptor {
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) {
        System.out.println("Checking authentication...");
        return true; // Continue to the controller
    }

    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) {
        System.out.println("Controller executed.");
    }
}

flow
============
Postman
  ↓
Servlet Container (Tomcat)
  ↓
Filter(s)
  ↓
DispatcherServlet
  ↓
Interceptor(s) - preHandle
  ↓
Controller
  ↓
Interceptor(s) - postHandle / afterCompletion
  ↓
Filter(s) (response phase)
  ↓
Postman
==============
controller-

@PostMapping("/upload")
public ResponseEntity<String> uploadFile(
        @RequestParam("file") MultipartFile file) throws IOException {

------
junit 5 annotataion
@ExtendWith(MockitoExtension.class)

@Mock, @InjectMocks

@MockBean only for Spring context tests

--
@ExtendWith(MockitoExtension.class)
class UserServiceCaptorTest {

    @Mock
    UserRepository userRepository;

    @InjectMocks
    UserService userService;

    @Captor
    ArgumentCaptor<User> userCaptor;

    @Test
    void createUser_capturesUser() {
        UserDto dto = new UserDto("John", "john@mail.com");

--
integration tesst..
@WebMvcTest(UserController.class)
class UserControllerTest {

    @Autowired
    MockMvc mockMvc;

    @MockBean
    UserService userService;
}
====




